History_NN The_DT Brown_JJ Corpus_NNP Research_NNP on_IN part-of-speech_JJ tagging_NN has_VBZ been_VBN closely_RB tied_VBN to_TO corpus_NN linguistics_NNS ._. The_DT first_JJ major_JJ corpus_NN of_IN English_NNP for_IN computer_NN analysis_NN was_VBD the_DT Brown_JJ Corpus_NNP developed_VBD at_IN Brown_NNP University_NNP by_IN Henry_NNP Kucera_NNP and_CC W._NNP Nelson_NNP Francis_NNP ,_, in_IN the_DT mid-1960s_NNS ._. It_PRP consists_VBZ of_IN about_IN 1,000,000_CD words_NNS of_IN running_VBG English_JJ prose_NN text_NN ,_, made_VBD up_RP of_IN 500_CD samples_NNS from_IN randomly_RB chosen_VBN publications_NNS ._. Each_DT sample_NN is_VBZ 2,000_CD or_CC more_JJR words_NNS -LRB-_-LRB- ending_VBG at_IN the_DT first_JJ sentence-end_NN after_IN 2,000_CD words_NNS ,_, so_RB that_IN the_DT corpus_NN contains_VBZ only_RB complete_JJ sentences_NNS -RRB-_-RRB- ._. The_DT Brown_NNP Corpus_NNP was_VBD painstakingly_RB ``_`` tagged_VBN ''_'' with_IN part-of-speech_JJ markers_NNS over_IN many_JJ years_NNS ._. A_DT first_JJ approximation_NN was_VBD done_VBN with_IN a_DT program_NN by_IN Greene_NNP and_CC Rubin_NNP ,_, which_WDT consisted_VBD of_IN a_DT huge_JJ handmade_NN list_NN of_IN what_WP categories_NNS could_MD co-occur_VB at_IN all_DT ._. For_IN example_NN ,_, article_NN then_RB noun_NN can_MD occur_VB ,_, but_CC article_NN then_RB verb_VB -LRB-_-LRB- arguably_RB -RRB-_-RRB- can_MD not_RB ._. The_DT program_NN got_VBD about_RB 70_CD correct_JJ ._. Its_PRP$ results_NNS were_VBD repeatedly_RB reviewed_VBN and_CC corrected_VBN by_IN hand_NN ,_, and_CC later_RB users_NNS sent_VBN in_IN errata_NNS so_IN that_IN by_IN the_DT late_JJ 70s_CD the_DT tagging_NN was_VBD nearly_RB perfect_JJ -LRB-_-LRB- allowing_VBG for_IN some_DT cases_NNS on_IN which_WDT even_RB human_JJ speakers_NNS might_MD not_RB agree_VB -RRB-_-RRB- ._. This_DT corpus_NN has_VBZ been_VBN used_VBN for_IN innumerable_JJ studies_NNS of_IN word-frequency_NN and_CC of_IN part-of-speech_NN and_CC inspired_VBD the_DT development_NN of_IN similar_JJ ``_`` tagged_VBN ''_'' corpora_NN in_IN many_JJ other_JJ languages_NNS ._. Statistics_NNS derived_VBN by_IN analyzing_VBG it_PRP formed_VBD the_DT basis_NN for_IN most_JJS later_RB part-of-speech_JJ tagging_NN systems_NNS ,_, such_JJ as_IN CLAWS_NNS and_CC VOLSUNGA_NNP ._. However_RB ,_, by_IN this_DT time_NN -LRB-_-LRB- 2005_CD -RRB-_-RRB- it_PRP has_VBZ been_VBN superseded_VBN by_IN larger_JJR corpora_NN such_JJ as_IN the_DT 100_CD million_CD word_NN British_NNP National_NNP Corpus_NNP ,_, even_RB though_IN larger_JJR corpora_NN are_VBP rarely_RB so_RB thoroughly_RB curated_VBN ._. For_IN some_DT time_NN ,_, part-of-speech_JJ tagging_NN was_VBD considered_VBN an_DT inseparable_JJ part_NN of_IN natural_JJ language_NN processing_NN ,_, because_IN there_EX are_VBP certain_JJ cases_NNS where_WRB the_DT correct_JJ part_NN of_IN speech_NN can_MD not_RB be_VB decided_VBN without_IN understanding_VBG the_DT semantics_NNS or_CC even_RB the_DT pragmatics_NNS of_IN the_DT context_NN ._. This_DT is_VBZ extremely_RB expensive_JJ ,_, especially_RB because_IN analyzing_VBG the_DT higher_JJR levels_NNS is_VBZ much_RB harder_JJR when_WRB multiple_JJ part-of-speech_JJ possibilities_NNS must_MD be_VB considered_VBN for_IN each_DT word_NN ._. Use_NN of_IN hidden_JJ Markov_NNP models_NNS In_IN the_DT mid-1980s_NNS ,_, researchers_NNS in_IN Europe_NNP began_VBD to_TO use_VB hidden_JJ Markov_NNP models_NNS -LRB-_-LRB- HMMs_NNS -RRB-_-RRB- to_TO disambiguate_VB parts_NNS of_IN speech_NN ,_, when_WRB working_VBG to_TO tag_VB the_DT Lancaster-Oslo-Bergen_NNP Corpus_NNP of_IN British_NNP English_NNP ._. HMMs_NNS involve_VBP counting_VBG cases_NNS -LRB-_-LRB- such_JJ as_IN from_IN the_DT Brown_JJ Corpus_NNP -RRB-_-RRB- and_CC making_VBG a_DT table_NN of_IN the_DT probabilities_NNS of_IN certain_JJ sequences_NNS ._. For_IN example_NN ,_, once_RB you_PRP 've_VBP seen_VBN an_DT article_NN such_JJ as_IN `_`` the_DT '_'' ,_, perhaps_RB the_DT next_JJ word_NN is_VBZ a_DT noun_NN 40_CD of_IN the_DT time_NN ,_, an_DT adjective_JJ 40_CD ,_, and_CC a_DT number_NN 20_CD ._. Knowing_VBG this_DT ,_, a_DT program_NN can_MD decide_VB that_IN ``_`` can_MD ''_'' in_IN ``_`` the_DT can_MD ''_'' is_VBZ far_RB more_RBR likely_JJ to_TO be_VB a_DT noun_NN than_IN a_DT verb_VBP or_CC a_DT modal_JJ ._. The_DT same_JJ method_NN can_MD ,_, of_IN course_NN ,_, be_VB used_VBN to_TO benefit_VB from_IN knowledge_NN about_IN the_DT following_VBG words_NNS ._. More_RBR advanced_JJ -LRB-_-LRB- ``_`` higher-order_JJ ''_'' -RRB-_-RRB- HMMs_NNS learn_VBP the_DT probabilities_NNS not_RB only_RB of_IN pairs_NNS but_CC triples_NNS or_CC even_RB larger_JJR sequences_NNS ._. So_RB ,_, for_IN example_NN ,_, if_IN you_PRP 've_VBP just_RB seen_VBN a_DT noun_NN followed_VBN by_IN a_DT verb_VBP ,_, the_DT next_JJ item_NN may_MD be_VB very_RB likely_RB a_DT preposition_NN ,_, article_NN ,_, or_CC noun_NN ,_, but_CC much_RB less_RBR likely_JJ another_DT verb_VB ._. When_WRB several_JJ ambiguous_JJ words_NNS occur_VBP together_RB ,_, the_DT possibilities_NNS multiply_VBP ._. However_RB ,_, it_PRP is_VBZ easy_JJ to_TO enumerate_VB every_DT combination_NN and_CC to_TO assign_VB a_DT relative_JJ probability_NN to_TO each_DT one_CD ,_, by_IN multiplying_VBG together_RB the_DT probabilities_NNS of_IN each_DT choice_NN in_IN turn_NN ._. The_DT combination_NN with_IN the_DT highest_JJS probability_NN is_VBZ then_RB chosen_VBN ._. The_DT European_JJ group_NN developed_VBD CLAWS_NNP ,_, a_DT tagging_VBG program_NN that_WDT did_VBD exactly_RB this_DT and_CC achieved_VBN accuracy_NN in_IN the_DT range_NN ._. Eugene_NNP Charniak_NNP points_VBZ out_RP in_IN Statistical_JJ techniques_NNS for_IN natural_JJ language_NN parsing_NN -LRB-_-LRB- 1997_CD -RRB-_-RRB- -LSB-_-LRB- 4_CD -RSB-_-RRB- that_WDT merely_RB assigning_VBG the_DT most_RBS common_JJ tag_NN to_TO each_DT known_VBN word_NN and_CC the_DT tag_NN ``_`` proper_JJ noun_NN ''_'' to_TO all_DT unknowns_NNS will_MD approach_VB 90_CD accuracy_NN because_IN many_JJ words_NNS are_VBP unambiguous_JJ ,_, and_CC many_JJ others_NNS only_RB rarely_RB represent_VB their_PRP$ less-common_JJ parts_NNS of_IN speech_NN ._. CLAWS_NN pioneered_VBD the_DT field_NN of_IN HMM-based_JJ part_NN of_IN speech_NN tagging_NN but_CC was_VBD quite_RB expensive_JJ since_IN it_PRP enumerated_VBD all_DT possibilities_NNS ._. It_PRP sometimes_RB had_VBD to_TO resort_VB to_TO backup_VB methods_NNS when_WRB there_EX were_VBD simply_RB too_RB many_JJ options_NNS -LRB-_-LRB- the_DT Brown_NNP Corpus_NNP contains_VBZ a_DT case_NN with_IN 17_CD ambiguous_JJ words_NNS in_IN a_DT row_NN ,_, and_CC there_EX are_VBP words_NNS such_JJ as_IN ``_`` still_RB ''_'' that_WDT can_MD represent_VB as_RB many_JJ as_IN 7_CD distinct_JJ parts_NNS of_IN speech_NN ._. -LSB-_-LRB- 5_CD -RSB-_-RRB- HMMs_NNS underlie_VBP the_DT functioning_NN of_IN stochastic_JJ taggers_NNS and_CC are_VBP used_VBN in_IN various_JJ algorithms_NNS one_CD of_IN the_DT most_RBS widely_RB used_VBN being_VBG the_DT bi-directional_JJ inference_NN algorithm_NN ._. -LSB-_-LRB- 6_CD -RSB-_-RRB- Dynamic_NNP programming_NN methods_NNS In_IN 1987_CD ,_, Steven_NNP DeRose_NNP -LSB-_-LRB- 7_CD -RSB-_-RRB- and_CC Kenneth_NNP W._NNP Church_NNP -LSB-_-LRB- 8_CD -RSB-_-RRB- independently_RB developed_VBD dynamic_JJ programming_NN algorithms_NNS to_TO solve_VB the_DT same_JJ problem_NN in_IN vastly_RB less_JJR time_NN ._. Their_PRP$ methods_NNS were_VBD similar_JJ to_TO the_DT Viterbi_NNP algorithm_NN known_VBN for_IN some_DT time_NN in_IN other_JJ fields_NNS ._. DeRose_NNP used_VBD a_DT table_NN of_IN pairs_NNS ,_, while_IN Church_NNP used_VBD a_DT table_NN of_IN triples_NNS and_CC a_DT method_NN of_IN estimating_VBG the_DT values_NNS for_IN triples_NNS that_WDT were_VBD rare_JJ or_CC nonexistent_JJ in_IN the_DT Brown_JJ Corpus_NNP -LRB-_-LRB- an_DT actual_JJ measurement_NN of_IN triple_JJ probabilities_NNS would_MD require_VB a_DT much_JJ larger_JJR corpus_NN -RRB-_-RRB- ._. Both_DT methods_NNS achieved_VBD an_DT accuracy_NN ._. DeRose_NNP 's_POS 1990_CD dissertation_NN at_IN Brown_NNP University_NNP included_VBD analyses_NNS of_IN the_DT specific_JJ error_NN types_NNS ,_, probabilities_NNS ,_, and_CC other_JJ related_JJ data_NNS ,_, and_CC replicated_VBD his_PRP$ work_NN for_IN Greek_JJ ,_, where_WRB it_PRP proved_VBD similarly_RB effective_JJ ._. These_DT findings_NNS were_VBD surprisingly_RB disruptive_JJ to_TO the_DT field_NN of_IN natural_JJ language_NN processing_NN ._. The_DT accuracy_NN reported_VBD was_VBD higher_JJR than_IN the_DT typical_JJ accuracy_NN of_IN very_RB sophisticated_JJ algorithms_NNS that_WDT integrated_VBN part_NN of_IN speech_NN choice_NN with_IN many_JJ higher_JJR levels_NNS of_IN linguistic_JJ analysis_NN :_: syntax_NN ,_, morphology_NN ,_, semantics_NNS ,_, and_CC so_RB on_IN ._. CLAWS_NNS ,_, DeRose_NNP 's_POS and_CC Church_NNP 's_POS methods_NNS did_VBD fail_VB for_IN some_DT of_IN the_DT known_JJ cases_NNS where_WRB semantics_NNS is_VBZ required_VBN ,_, but_CC those_DT proved_VBN negligibly_RB rare_JJ ._. This_DT convinced_JJ many_JJ in_IN the_DT field_NN that_WDT part-of-speech_JJ tagging_NN could_MD usefully_RB be_VB separated_VBN from_IN the_DT other_JJ levels_NNS of_IN processing_NN ;_: this_DT ,_, in_IN turn_NN ,_, simplified_VBD the_DT theory_NN and_CC practice_NN of_IN computerized_JJ language_NN analysis_NN and_CC encouraged_VBD researchers_NNS to_TO find_VB ways_NNS to_TO separate_VB other_JJ pieces_NNS as_RB well_RB ._. Markov_NNP Models_NNS became_VBD the_DT standard_JJ method_NN for_IN the_DT part-of-speech_JJ assignment_NN ._. Unsupervised_JJ taggers_NNS The_DT methods_NNS already_RB discussed_VBN involve_VBP working_VBG from_IN a_DT pre-existing_JJ corpus_NN to_TO learn_VB tag_NN probabilities_NNS ._. It_PRP is_VBZ ,_, however_RB ,_, also_RB possible_JJ to_TO bootstrap_VB using_VBG ``_`` unsupervised_JJ ''_'' tagging_NN ._. Unsupervised_JJ tagging_NN techniques_NNS use_VBP an_DT untagged_JJ corpus_NN for_IN their_PRP$ training_NN data_NNS and_CC produce_VBP the_DT tagset_NN by_IN induction_NN ._. That_DT is_VBZ ,_, they_PRP observe_VBP patterns_NNS in_IN word_NN use_NN ,_, and_CC derive_VBP part-of-speech_JJ categories_NNS themselves_PRP ._. For_IN example_NN ,_, statistics_NNS readily_RB reveal_VBP that_IN ``_`` the_DT ''_'' ,_, ``_`` a_DT ''_'' ,_, and_CC ``_`` an_DT ''_'' occur_VB in_IN similar_JJ contexts_NNS ,_, while_IN ``_`` eat_VB ''_'' occurs_VBZ in_IN very_RB different_JJ ones_NNS ._. With_IN sufficient_JJ iteration_NN ,_, similarity_NN classes_NNS of_IN words_NNS emerge_VBP that_DT are_VBP remarkably_RB similar_JJ to_TO those_DT human_JJ linguists_NNS would_MD expect_VB ;_: and_CC the_DT differences_NNS themselves_PRP sometimes_RB suggest_VBP valuable_JJ new_JJ insights_NNS ._. These_DT two_CD categories_NNS can_MD be_VB further_JJ subdivided_VBN into_IN rule-based_JJ ,_, stochastic_JJ ,_, and_CC neural_JJ approaches_NNS ._. Other_JJ taggers_NNS and_CC methods_NNS Some_DT current_JJ major_JJ algorithms_NNS for_IN part-of-speech_JJ tagging_NN include_VBP the_DT Viterbi_NNP algorithm_NN ,_, Brill_NNP tagger_NN ,_, Constraint_NNP Grammar_NNP ,_, and_CC the_DT Baum-Welch_NNP algorithm_NN -LRB-_-LRB- also_RB known_VBN as_IN the_DT forward-backward_JJ algorithm_NN -RRB-_-RRB- ._. Hidden_NNP Markov_NNP model_NN and_CC visible_JJ Markov_NNP model_NN taggers_NNS can_MD both_DT be_VB implemented_VBN using_VBG the_DT Viterbi_NNP algorithm_NN ._. The_DT rule-based_JJ Brill_NNP tagger_NN is_VBZ unusual_JJ in_IN that_IN it_PRP learns_VBZ a_DT set_NN of_IN rule_NN patterns_NNS ,_, and_CC then_RB applies_VBZ those_DT patterns_NNS rather_RB than_IN optimizing_VBG a_DT statistical_JJ quantity_NN ._. Many_JJ machine_NN learning_VBG methods_NNS have_VBP also_RB been_VBN applied_VBN to_TO the_DT problem_NN of_IN POS_NN tagging_NN ._. Methods_NNS such_JJ as_IN SVM_NN ,_, maximum_NN entropy_NN classifier_NN ,_, perceptron_NN ,_, and_CC nearest-neighbor_NN have_VBP all_DT been_VBN tried_VBN ,_, and_CC most_JJS can_MD achieve_VB accuracy_NN ._. A_DT direct_JJ comparison_NN of_IN several_JJ methods_NNS is_VBZ reported_VBN -LRB-_-LRB- with_IN references_NNS -RRB-_-RRB- at_IN the_DT ACL_NN Wiki_NN ._. -LSB-_-LRB- 9_CD -RSB-_-RRB- This_DT comparison_NN uses_VBZ the_DT Penn_NNP tag_NN set_VBN on_IN some_DT of_IN the_DT Penn_NNP Treebank_NNP data_NNS ,_, so_IN the_DT results_NNS are_VBP directly_RB comparable_JJ ._. However_RB ,_, many_JJ significant_JJ taggers_NNS are_VBP not_RB included_VBN -LRB-_-LRB- perhaps_RB because_IN of_IN the_DT labor_NN involved_VBN in_IN reconfiguring_VBG them_PRP for_IN this_DT particular_JJ dataset_NN -RRB-_-RRB- ._. Thus_RB ,_, it_PRP should_MD not_RB be_VB assumed_VBN that_IN the_DT results_NNS reported_VBN here_RB are_VBP the_DT best_JJS that_WDT can_MD be_VB achieved_VBN with_IN a_DT given_VBN approach_NN ;_: nor_CC even_RB the_DT best_JJS that_WDT have_VBP been_VBN achieved_VBN with_IN a_DT given_VBN approach_NN ._. 
Part-of-speech_JJ tagging_NN is_VBZ harder_JJR than_IN just_RB having_VBG a_DT list_NN of_IN words_NNS and_CC their_PRP$ parts_NNS of_IN speech_NN ,_, because_IN some_DT words_NNS can_MD represent_VB more_JJR than_IN one_CD part_NN of_IN speech_NN at_IN different_JJ times_NNS ,_, and_CC because_IN some_DT parts_NNS of_IN speech_NN are_VBP complex_JJ ._. This_DT is_VBZ not_RB rare_JJ --_: in_IN natural_JJ languages_NNS -LRB-_-LRB- as_IN opposed_VBN to_TO many_JJ artificial_JJ languages_NNS -RRB-_-RRB- ,_, a_DT large_JJ percentage_NN of_IN word-forms_NNS are_VBP ambiguous_JJ ._. For_IN example_NN ,_, even_RB ``_`` dogs_NNS ''_'' ,_, which_WDT is_VBZ usually_RB thought_VBN of_IN as_RB just_RB a_DT plural_NN noun_NN ,_, can_MD also_RB be_VB a_DT verb_VB :_: The_DT sailor_NN dogs_VBZ the_DT hatch_NN ._. Correct_JJ grammatical_JJ tagging_NN will_MD reflect_VB that_IN ``_`` dogs_NNS ''_'' is_VBZ here_RB used_VBN as_IN a_DT verb_VBP ,_, not_RB as_IN the_DT more_RBR common_JJ plural_NN noun_NN ._. Grammatical_JJ context_NN is_VBZ one_CD way_NN to_TO determine_VB this_DT ;_: semantic_JJ analysis_NN can_MD also_RB be_VB used_VBN to_TO infer_VB that_IN ``_`` sailor_NN ''_'' and_CC ``_`` hatch_NN ''_'' implicate_VBP ``_`` dogs_NNS ''_'' as_IN 1_CD -RRB-_-RRB- in_IN the_DT nautical_JJ context_NN and_CC 2_LS -RRB-_-RRB- an_DT action_NN applied_VBD to_TO the_DT object_NN ``_`` hatch_NN ''_'' -LRB-_-LRB- in_IN this_DT context_NN ,_, ``_`` dogs_NNS ''_'' is_VBZ a_DT nautical_JJ term_NN meaning_NN ``_`` fastens_NNS -LRB-_-LRB- a_DT watertight_JJ door_NN -RRB-_-RRB- securely_RB ''_'' -RRB-_-RRB- ._. Tag_NN sets_VBZ Schools_NNP commonly_RB teach_VBP that_IN there_EX are_VBP 9_CD parts_NNS of_IN speech_NN in_IN English_NNP :_: noun_NN ,_, verb_VB ,_, article_NN ,_, adjective_NN ,_, preposition_NN ,_, pronoun_NN ,_, adverb_NN ,_, conjunction_NN ,_, and_CC interjection_NN ._. However_RB ,_, there_EX are_VBP clearly_RB many_JJ more_JJR categories_NNS and_CC sub-categories_NNS ._. For_IN nouns_NNS ,_, the_DT plural_NN ,_, possessive_JJ ,_, and_CC singular_JJ forms_NNS can_MD be_VB distinguished_VBN ._. In_IN many_JJ languages_NNS words_NNS are_VBP also_RB marked_VBN for_IN their_PRP$ ``_`` case_NN ''_'' -LRB-_-LRB- role_NN as_IN subject_JJ ,_, object_NN ,_, etc._FW -RRB-_-RRB- ,_, grammatical_JJ gender_NN ,_, and_CC so_RB on_IN ;_: while_IN verbs_NNS are_VBP marked_VBN for_IN tense_JJ ,_, aspect_NN ,_, and_CC other_JJ things_NNS ._. In_IN some_DT tagging_VBG systems_NNS ,_, different_JJ inflections_NNS of_IN the_DT same_JJ root_NN word_NN will_MD get_VB different_JJ parts_NNS of_IN speech_NN ,_, resulting_VBG in_IN a_DT large_JJ number_NN of_IN tags_NNS ._. For_IN example_NN ,_, NN_NNP for_IN singular_JJ common_JJ nouns_NNS ,_, NNS_NN for_IN plural_NN common_JJ nouns_NNS ,_, NP_NN for_IN singular_JJ proper_JJ nouns_NNS -LRB-_-LRB- see_VB the_DT POS_NN tags_NNS used_VBN in_IN the_DT Brown_JJ Corpus_NNP -RRB-_-RRB- ._. Other_JJ tagging_VBG systems_NNS use_VBP a_DT smaller_JJR number_NN of_IN tags_NNS and_CC ignore_VB fine_JJ differences_NNS or_CC model_NN them_PRP as_IN features_NNS somewhat_RB independent_JJ from_IN part-of-speech_JJ ._. -LSB-_-LRB- 2_CD -RSB-_-RRB- In_IN part-of-speech_JJ tagging_NN by_IN computer_NN ,_, it_PRP is_VBZ typical_JJ to_TO distinguish_VB from_IN 50_CD to_TO 150_CD separate_JJ parts_NNS of_IN speech_NN for_IN English_NNP ._. Work_NN on_IN stochastic_JJ methods_NNS for_IN tagging_VBG Koine_NNP Greek_JJ -LRB-_-LRB- DeRose_JJ 1990_CD -RRB-_-RRB- has_VBZ used_VBN over_IN 1,000_CD parts_NNS of_IN speech_NN and_CC found_VBD that_IN about_RB as_RB many_JJ words_NNS were_VBD ambiguous_JJ in_IN that_DT language_NN as_RB in_IN English_NNP ._. A_DT morphosyntactic_JJ descriptor_NN in_IN the_DT case_NN of_IN morphologically_RB rich_JJ languages_NNS is_VBZ commonly_RB expressed_VBN using_VBG very_RB short_JJ mnemonics_NNS ,_, such_JJ as_IN Ncmsan_NNP for_IN Category_NNP =_JJ Noun_NN ,_, Type_NN =_JJ common_JJ ,_, Gender_NN =_JJ masculine_JJ ,_, Number_NN =_JJ singular_JJ ,_, Case_NN =_JJ accusative_JJ ,_, Animate_NN =_JJ no_DT ._. The_DT most_RBS popular_JJ ``_`` tag_NN set_NN ''_'' for_IN POS_NN tagging_VBG for_IN American_JJ English_NNP is_VBZ probably_RB the_DT Penn_NNP tag_NN set_NN ,_, developed_VBN in_IN the_DT Penn_NNP Treebank_NNP project_NN ._. It_PRP is_VBZ largely_RB similar_JJ to_TO the_DT earlier_JJR Brown_JJ Corpus_NNP and_CC LOB_NNP Corpus_NNP tag_NN sets_NNS ,_, though_RB much_RB smaller_JJR ._. In_IN Europe_NNP ,_, tag_NN sets_NNS from_IN the_DT Eagles_NNPS Guidelines_NNS see_VBP wide_JJ use_NN and_CC include_VBP versions_NNS for_IN multiple_JJ languages_NNS ._. POS_NN tagging_NN work_NN has_VBZ been_VBN done_VBN in_IN a_DT variety_NN of_IN languages_NNS ,_, and_CC the_DT set_NN of_IN POS_NN tags_NNS used_VBN varies_VBZ greatly_RB with_IN language_NN ._. Tags_NNS usually_RB are_VBP designed_VBN to_TO include_VB overt_JJ morphological_JJ distinctions_NNS ,_, although_IN this_DT leads_VBZ to_TO inconsistencies_NNS such_JJ as_IN case-marking_NN for_IN pronouns_NNS but_CC not_RB nouns_NNS in_IN English_NNP ,_, and_CC much_RB larger_JJR cross-language_JJ differences_NNS ._. The_DT tag_NN sets_VBZ for_IN heavily_RB inflected_VBN languages_NNS such_JJ as_IN Greek_JJ and_CC Latin_NNP can_MD be_VB very_RB large_JJ ;_: tagging_VBG words_NNS in_IN agglutinative_JJ languages_NNS such_JJ as_IN Inuit_NNP languages_NNS may_MD be_VB virtually_RB impossible_JJ ._. At_IN the_DT other_JJ extreme_JJ ,_, Petrov_NNP et_FW al._FW -LSB-_-LRB- 3_CD -RSB-_-RRB- have_VBP proposed_VBN a_DT ``_`` universal_JJ ''_'' tag_NN set_NN ,_, with_IN 12_CD categories_NNS -LRB-_-LRB- for_IN example_NN ,_, no_DT subtypes_NNS of_IN nouns_NNS ,_, verbs_NNS ,_, punctuation_NN ,_, and_CC so_RB on_IN -RRB-_-RRB- ._. Whether_IN a_DT very_RB small_JJ set_NN of_IN very_RB broad_JJ tags_NNS or_CC a_DT much_RB larger_JJR set_NN of_IN more_JJR precise_JJ ones_NNS is_VBZ preferable_JJ ,_, depends_VBZ on_IN the_DT purpose_NN at_IN hand_NN ._. Automatic_NNP tagging_NN is_VBZ easier_JJR on_IN smaller_JJR tag-sets_NNS ._. In_IN corpus_NN linguistics_NNS ,_, part-of-speech_JJ tagging_NN -LRB-_-LRB- POS_NN tagging_NN or_CC PoS_NN tagging_NN or_CC POST_NN -RRB-_-RRB- ,_, also_RB called_VBN grammatical_JJ tagging_NN is_VBZ the_DT process_NN of_IN marking_VBG up_RP a_DT word_NN in_IN a_DT text_NN -LRB-_-LRB- corpus_NN -RRB-_-RRB- as_IN corresponding_VBG to_TO a_DT particular_JJ part_NN of_IN speech_NN ,_, -LSB-_-LRB- 1_CD -RSB-_-RRB- based_VBN on_IN both_DT its_PRP$ definition_NN and_CC its_PRP$ context_NN ._. A_DT simplified_VBN form_NN of_IN this_DT is_VBZ commonly_RB taught_VBN to_TO school-age_JJ children_NNS ,_, in_IN the_DT identification_NN of_IN words_NNS as_IN nouns_NNS ,_, verbs_NNS ,_, adjectives_NNS ,_, adverbs_NNS ,_, etc._FW ._. Once_RB performed_VBN by_IN hand_NN ,_, POS_NN tagging_NN is_VBZ now_RB done_VBN in_IN the_DT context_NN of_IN computational_JJ linguistics_NNS ,_, using_VBG algorithms_NNS which_WDT associate_VBP discrete_JJ terms_NNS ,_, as_RB well_RB as_IN hidden_JJ parts_NNS of_IN speech_NN ,_, by_IN a_DT set_NN of_IN descriptive_JJ tags_NNS ._. POS-tagging_JJ algorithms_NNS fall_VBP into_IN two_CD distinctive_JJ groups_NNS :_: rule-based_JJ and_CC stochastic_JJ ._. E._NNP Brill_NNP 's_POS tagger_NN ,_, one_CD of_IN the_DT first_JJ and_CC most_JJS widely_RB used_JJ English_JJ POS-taggers_NNS ,_, employs_VBZ rule-based_JJ algorithms_NNS ._. 